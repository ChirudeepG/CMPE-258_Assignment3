{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFI8nrjjjsYbmUfOT9MlQm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChirudeepG/CMPE-258-Assignment2/blob/main/2B_using_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uPrChWAypWrF"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scalar vector multiplication"
      ],
      "metadata": {
        "id": "xgh2PabHpoYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand(1)\n",
        "b = torch.rand(4, 6)\n",
        "mult = torch.einsum('i, ij -> ij', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(mult)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofCDmrFbqK_z",
        "outputId": "49c9f636-bfeb-4e11-a6be-3356f846bfa3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3313])\n",
            "tensor([[0.4851, 0.4064, 0.8049, 0.3850, 0.0183, 0.8725],\n",
            "        [0.6522, 0.7195, 0.0587, 0.8466, 0.8328, 0.6004],\n",
            "        [0.6877, 0.3292, 0.2900, 0.6872, 0.4416, 0.9597],\n",
            "        [0.4194, 0.1896, 0.1505, 0.1915, 0.1617, 0.4004]])\n",
            "tensor([[0.1607, 0.1346, 0.2666, 0.1275, 0.0061, 0.2890],\n",
            "        [0.2161, 0.2384, 0.0195, 0.2805, 0.2759, 0.1989],\n",
            "        [0.2278, 0.1090, 0.0961, 0.2277, 0.1463, 0.3179],\n",
            "        [0.1389, 0.0628, 0.0499, 0.0634, 0.0536, 0.1326]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vector vector multiplication"
      ],
      "metadata": {
        "id": "h1ZkPpawqO59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand(2, 6)\n",
        "b = torch.rand(6, 3)\n",
        "mult = torch.einsum('ij, jk -> ik', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(mult)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qs5lm1apqYqD",
        "outputId": "6c966956-7cbe-4f57-aa63-e6cc471445d6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9774, 0.1520, 0.7850, 0.4123, 0.9935, 0.7522],\n",
            "        [0.2617, 0.9254, 0.2538, 0.9307, 0.5132, 0.2324]])\n",
            "tensor([[0.9386, 0.8450, 0.2563],\n",
            "        [0.7607, 0.5866, 0.1757],\n",
            "        [0.1255, 0.8354, 0.3142],\n",
            "        [0.6979, 0.7214, 0.8781],\n",
            "        [0.3365, 0.6935, 0.3320],\n",
            "        [0.5362, 0.8716, 0.4842]])\n",
            "tensor([[2.1570, 3.2130, 1.5801],\n",
            "        [1.9282, 2.2059, 1.4096]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scalar dot product"
      ],
      "metadata": {
        "id": "8UGTEZR1qiQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.arange(9).reshape(3, 3)\n",
        "b = torch.arange(6).reshape(3, 2)\n",
        "prod = torch.einsum('ij, jk ->', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(prod)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qoqM55tqjUy",
        "outputId": "09646536-ec29-4a91-a6e2-56cfb737782a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n",
            "tensor([[0, 1],\n",
            "        [2, 3],\n",
            "        [4, 5]])\n",
            "tensor(204)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Outer product"
      ],
      "metadata": {
        "id": "4wQxeGHNq6wb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.arange(8)\n",
        "b = torch.arange(4, 6)  \n",
        "prod = torch.einsum('i,j -> ij', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(prod)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVuvi-f8q2yL",
        "outputId": "81c6d607-45c7-4fbc-c8f8-a5f93ab2a06b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3, 4, 5, 6, 7])\n",
            "tensor([4, 5])\n",
            "tensor([[ 0,  0],\n",
            "        [ 4,  5],\n",
            "        [ 8, 10],\n",
            "        [12, 15],\n",
            "        [16, 20],\n",
            "        [20, 25],\n",
            "        [24, 30],\n",
            "        [28, 35]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hadamard product"
      ],
      "metadata": {
        "id": "XT-hdG3erEXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.arange(8).reshape(2, 4)\n",
        "b = torch.arange(4, 12).reshape(2, 4)\n",
        "prod = torch.einsum('ij, ij -> ij', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(prod)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Jc_mJ_7rBhr",
        "outputId": "5f163253-cf6c-4195-9589-da6422e0ae89"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2, 3],\n",
            "        [4, 5, 6, 7]])\n",
            "tensor([[ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "tensor([[ 0,  5, 12, 21],\n",
            "        [32, 45, 60, 77]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch matrix multiplication"
      ],
      "metadata": {
        "id": "UK3vM4OyrTpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(3, 3, 5)\n",
        "b = torch.randn(3, 5, 2)\n",
        "batch_mult = torch.einsum('bij, bjk -> bik', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(batch_mult)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HStddLPJrPQb",
        "outputId": "0a56342c-96e0-41f7-bd32-f1fc420d12b7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 1.5254,  1.9199, -0.4792,  2.0774,  0.6855],\n",
            "         [-0.5178,  0.5267,  0.2078,  0.0098,  2.3039],\n",
            "         [ 1.6595,  2.9954, -0.6341, -0.1312,  0.8082]],\n",
            "\n",
            "        [[-0.8789, -1.7089,  0.4529, -0.3293,  1.4509],\n",
            "         [-0.7451,  0.0403, -0.0705,  0.4589,  1.8620],\n",
            "         [ 0.2497,  0.9242, -1.9819, -0.4972,  0.9077]],\n",
            "\n",
            "        [[ 1.3157,  0.5770, -0.9078,  1.0450,  0.1962],\n",
            "         [-0.6498,  0.7053, -1.0756, -2.1783, -1.1061],\n",
            "         [ 0.6627, -0.9473, -0.4753,  1.6333,  0.0504]]])\n",
            "tensor([[[-0.1141,  0.3403],\n",
            "         [ 1.2995, -0.2421],\n",
            "         [ 0.6156, -0.6098],\n",
            "         [ 1.2012, -0.2054],\n",
            "         [-0.0827, -0.7634]],\n",
            "\n",
            "        [[ 1.1351, -0.0634],\n",
            "         [-1.1535,  0.6026],\n",
            "         [-0.9650, -0.5978],\n",
            "         [ 0.2094, -0.5810],\n",
            "         [ 1.0234,  0.2286]],\n",
            "\n",
            "        [[-1.5108, -0.7440],\n",
            "         [ 0.9855,  1.5039],\n",
            "         [ 0.3154, -0.2467],\n",
            "         [ 0.2673, -1.2389],\n",
            "         [ 1.0570,  1.2580]]])\n",
            "tensor([[[ 4.4646, -0.6036],\n",
            "         [ 0.6927, -2.1912],\n",
            "         [ 3.0886, -0.3638]],\n",
            "\n",
            "        [[ 1.9523, -0.7219],\n",
            "         [ 1.1774,  0.2727],\n",
            "         [ 1.9548,  2.2223]],\n",
            "\n",
            "        [[-1.2189, -0.9351],\n",
            "         [-0.4139,  3.1168],\n",
            "         [-1.5949, -3.7606]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor reduction"
      ],
      "metadata": {
        "id": "lKEuD2IXrgWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(2, 3, 5, 7)\n",
        "b = torch.randn(4, 1, 3, 11, 5)\n",
        "reduction = torch.einsum('pqrs, tuqvr -> pstuv', [a, b])\n",
        "print(a.shape, b.shape, reduction.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SmpDhBxrcSd",
        "outputId": "f40f51dc-ffb4-4993-f009-d4626eaf8c86"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 5, 7]) torch.Size([4, 1, 3, 11, 5]) torch.Size([2, 7, 4, 1, 11])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transpose"
      ],
      "metadata": {
        "id": "2eQEOlqCrugy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.arange(8).reshape(4, 2)\n",
        "transpose = torch.einsum('ij -> ji', [a])\n",
        "print(a)\n",
        "print(transpose)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7r83yWc0rsPC",
        "outputId": "5c51a36f-e276-49a8-d99e-c8a28acc801f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1],\n",
            "        [2, 3],\n",
            "        [4, 5],\n",
            "        [6, 7]])\n",
            "tensor([[0, 2, 4, 6],\n",
            "        [1, 3, 5, 7]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bilinear transformation"
      ],
      "metadata": {
        "id": "TDGefAejsCjj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(2, 3)\n",
        "b = torch.randn(3, 3, 4)\n",
        "c = torch.randn(2, 4)\n",
        "bilinear = torch.einsum('ik, jkl, il -> ij', [a, b, c])\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n",
        "print(bilinear)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhUJUCBbr-bS",
        "outputId": "117fc0ab-12fe-4270-d7c3-c6c53797bf08"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.0398, -0.0277, -1.4539],\n",
            "        [ 2.3286,  0.2773,  0.1847]])\n",
            "tensor([[[-1.9473, -0.7830, -0.3186,  0.2888],\n",
            "         [ 0.3462,  1.7144, -0.1409, -1.8719],\n",
            "         [ 0.3154, -1.0503,  0.5024, -0.7901]],\n",
            "\n",
            "        [[-0.4666,  1.1429,  1.2826,  0.0789],\n",
            "         [ 0.9225, -1.4927,  0.6351, -0.5602],\n",
            "         [-0.0954,  0.4608, -0.5915,  0.9831]],\n",
            "\n",
            "        [[-0.6762, -1.7044, -1.1853,  0.6254],\n",
            "         [ 1.0133, -2.1496,  1.2599, -0.7597],\n",
            "         [-0.8118,  0.1142, -0.8986,  0.1337]]])\n",
            "tensor([[-0.5186, -0.7824, -1.7112,  1.4743],\n",
            "        [-0.0416,  0.8856,  0.6247, -0.0125]])\n",
            "tensor([[-0.5983, -0.2532, -7.7644],\n",
            "        [-1.6134,  4.0059, -5.5894]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attention"
      ],
      "metadata": {
        "id": "SPlGh6QVsM0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_tensors(shape, num=1, requires_grad=False):\n",
        "  tensors = [torch.randn(shape, requires_grad=requires_grad) for i in range(0, num)]\n",
        "  return tensors[0] if num == 1 else tensors\n",
        "bM, br, w = random_tensors([7], num=3, requires_grad=True)\n",
        "WY, Wh, Wr, Wt = random_tensors([7, 7], num=4, requires_grad=True)\n",
        "\n",
        "def attention(Y, ht, rt1):\n",
        "  tmp = torch.einsum('ik, kl -> il', [ht, Wh]) + torch.einsum('ik, kl -> il', [rt1, Wr])\n",
        "  Mt = torch.tanh(torch.einsum('ijk, kl -> ijl', [Y, WY]) + tmp.unsqueeze(1).expand_as(Y) + bM)\n",
        "  at = torch.nn.functional.softmax(torch.einsum('ijk, k -> ij', [Mt, w])) \n",
        "  rt = torch.einsum('ijk, ij -> ik', [Y, at]) + torch.tanh(torch.einsum('ij, jk -> ik', [rt1, Wt]) + br)\n",
        "  \n",
        "  return rt, at\n",
        "Y = torch.randn(3,5,7)\n",
        "ht, rt1 = random_tensors([3, 7], num=2)\n",
        "\n",
        "rt, at = attention(Y, ht, rt1)\n",
        "\n",
        "print(at)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mO3IpzwIsGLK",
        "outputId": "e2a65813-c056-4524-c32d-208d35f903a5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1610, 0.0267, 0.6410, 0.1368, 0.0345],\n",
            "        [0.3120, 0.1405, 0.2352, 0.0782, 0.2341],\n",
            "        [0.6287, 0.0624, 0.0550, 0.0322, 0.2216]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-7de9fe594675>:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  at = torch.nn.functional.softmax(torch.einsum('ijk, k -> ij', [Mt, w]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treeqn"
      ],
      "metadata": {
        "id": "p1lQYkIPsbmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transition(zl):\n",
        "  return zl.unsqueeze(1) + torch.tanh(torch.einsum('bk, aki -> bai', [zl, W]) + b)\n",
        "zl = torch.randn(2, 3)\n",
        "b = torch.randn(5, 3)\n",
        "W = torch.randn(5, 3, 3)\n",
        "\n",
        "transition(zl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lphDcC4WsYxW",
        "outputId": "850c91ae-6a92-49a2-dc4c-76729adb32a7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0906, -0.1373, -1.3560],\n",
              "         [-1.3797,  0.6889, -0.2883],\n",
              "         [ 0.0166, -0.6216,  0.5134],\n",
              "         [-1.6399,  1.0142, -0.7237],\n",
              "         [-0.1018, -0.7245, -0.3301]],\n",
              "\n",
              "        [[-1.7863, -2.5117, -0.4432],\n",
              "         [-1.1353, -0.5883,  1.4673],\n",
              "         [-1.7590, -2.2952,  1.5078],\n",
              "         [-0.8271, -0.5944,  0.2364],\n",
              "         [-0.6205, -1.8291,  0.2456]]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}